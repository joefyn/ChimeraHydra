#!/usr/bin/env python3"""Validate JSON artifacts against JSON Schemas with configurable traversal depth and strict dialect checks.Behavior:- In hard-fail mode (--fail-on-invalid), exit 1 if any artifact is invalid, if required schemas are missing, or if no artifacts are found to validate.- In soft mode (default), print a summary but exit 0.All code and comments are ASCII-only."""import argparseimport jsonimport osimport sysimport pathlibfrom typing import Any, Dict, Iterable, List, Optional, Set, Tuplefrom jsonschema import Draft202012Validator, Draft201909Validator, Draft7Validator, ValidationErrortry:    # RefResolver is deprecated in jsonschema 4.x but available for simple local $ref resolution.    from jsonschema import RefResolver  # type: ignoreexcept Exception:  # pragma: no cover    RefResolver = None  # type: ignore# Map of artifact file name -> corresponding schema file nameSCHEMA_MAP: Dict[str, str] = {    "prompt.audit.json": "prompt.audit.schema.json",    "code.plan.json": "code.plan.schema.json",    "codex.instructions.json": "codex.instructions.schema.json",}DIALECT_CHOICES = ("2020-12", "2019-09", "draft7")def parse_args() -> argparse.Namespace:    p = argparse.ArgumentParser(description="Validate generated artifacts against JSON Schemas.")    p.add_argument("--schemas-dir", default="schemas", help="Directory containing JSON schema files.")    p.add_argument("--artifacts-dir", default="artifacts", help="Root directory containing artifact runs.")    p.add_argument("--dialect", default="2020-12", choices=DIALECT_CHOICES, help="Schema dialect to enforce and use for validation.")    p.add_argument("--fail-on-invalid", action="store_true", help="Exit non-zero on invalid artifacts or missing setup.")    p.add_argument("--max-depth", type=int, default=2, help="Max directory depth under artifacts-dir to descend. 0 means unlimited.")    p.add_argument("--strict-dialect", action="store_true", default=True, help="Treat schema dialect mismatches as invalid.")    p.add_argument("--no-strict-dialect", action="store_false", dest="strict_dialect", help="Do not fail on dialect mismatch. Only warn.")    p.add_argument("--quiet", action="store_true", help="Reduce non-error output.")    return p.parse_args()def expected_schema_uris(dialect: str) -> Set[str]:    if dialect == "2020-12":        return {            "https://json-schema.org/draft/2020-12/schema",            "http://json-schema.org/draft/2020-12/schema",        }    if dialect == "2019-09":        return {            "https://json-schema.org/draft/2019-09/schema",            "http://json-schema.org/draft/2019-09/schema",        }    if dialect == "draft7":        return {            "https://json-schema.org/draft-07/schema",            "http://json-schema.org/draft-07/schema",        }    return set()def infer_draft(schema_uri: Optional[str]) -> str:    if not schema_uri:        return "missing"    s = schema_uri.lower()    if "2020-12" in s:        return "2020-12"    if "2019-09" in s:        return "2019-09"    if "draft-07" in s or "draft7" in s:        return "draft7"    return "unknown"def load_schemas(schemas_dir: pathlib.Path, hard: bool, dialect: str, quiet: bool) -> Tuple[Dict[str, Any], Dict[str, Any], List[Tuple[str, str]]]:    schemas: Dict[str, Any] = {}    store: Dict[str, Any] = {}    issues: List[Tuple[str, str]] = []    expected = expected_schema_uris(dialect)    for sch in sorted(set(SCHEMA_MAP.values())):        p = schemas_dir / sch        if not p.exists():            print(f"missing schema: {p}")            if hard:                sys.exit(1)            else:                continue        try:            obj = json.loads(p.read_text(encoding="utf-8"))        except json.JSONDecodeError as e:            print(f"schema parse error: {p}: {e}")            if hard:                sys.exit(1)            else:                continue        # Dialect check against $schema        found_uri = None        if isinstance(obj, dict):            found_uri = obj.get("$schema")  # type: ignore[assignment]        found_draft = infer_draft(found_uri)        if found_uri not in expected:            expected_list = ", ".join(sorted(expected))            details = (                f"dialect-mismatch: {p} found={found_uri if found_uri else 'missing'} "                f"inferred={found_draft} expected_one_of={{ {expected_list} }}. "                f"impact=validator set to {dialect}; cross-draft validation may be inaccurate. "                f"suggested_fix=set top-level $schema to one of: {expected_list}"            )            issues.append((str(p), details))            if not quiet:                print(f"warning: {details}")        schemas[sch] = obj        store[p.resolve().as_uri()] = obj    return schemas, store, issuesdef make_validator(schema_obj: Any, schemas_dir: pathlib.Path, store: Dict[str, Any], dialect: str):    # Choose validator by requested dialect    if dialect == "2020-12":        ValidatorClass = Draft202012Validator    elif dialect == "2019-09":        ValidatorClass = Draft201909Validator    else:        ValidatorClass = Draft7Validator    if RefResolver is None:        return ValidatorClass(schema_obj)    base_uri = schemas_dir.resolve().as_uri().rstrip("/") + "/"    return ValidatorClass(schema_obj, resolver=RefResolver(base_uri=base_uri, store=store))def depth_from_root(root: pathlib.Path, path: pathlib.Path) -> int:    try:        rel = path.relative_to(root)    except ValueError:        return 0    parts = [p for p in rel.parts if p not in (".", "")]    return len(parts)def iter_candidate_dirs(root: pathlib.Path, max_depth: int) -> Iterable[pathlib.Path]:    # Walk deterministically and yield dirs that contain at least one mapped artifact filename.    if not root.exists():        return    # os.walk traversal    for cur_dir, dirnames, filenames in os.walk(root):        # Sort for determinism        dirnames.sort()        filenames_sorted = sorted(filenames)        cur_path = pathlib.Path(cur_dir)        if max_depth > 0:            cur_depth = depth_from_root(root, cur_path)            # If we are already at max depth, do not descend further            if cur_depth >= max_depth:                dirnames[:] = []        # If any mapped artifact exists in this directory, treat it as a run dir        for artifact_name in SCHEMA_MAP.keys():            if artifact_name in filenames_sorted:                yield cur_path                breakdef validate_dir(run_dir: pathlib.Path, schemas: Dict[str, Any], schemas_dir: pathlib.Path, store: Dict[str, Any], dialect: str) -> List[Tuple[str, str, str]]:    invalid: List[Tuple[str, str, str]] = []    for art_name, sch_name in SCHEMA_MAP.items():        art_path = run_dir / art_name        if not art_path.exists():            continue        try:            data = json.loads(art_path.read_text(encoding="utf-8"))        except Exception as e:            invalid.append((str(art_path), f"json-parse-error", f"{e}"))            continue        schema = schemas.get(sch_name)        if not schema:            invalid.append((str(art_path), "schema-missing", sch_name))            continue        validator = make_validator(schema, schemas_dir, store, dialect)        try:            validator.validate(data)        except ValidationError as e:            invalid.append((str(art_path), f"schema: {sch_name}", f"error: {e.message}"))    return invaliddef main() -> int:    args = parse_args()    schemas_dir = pathlib.Path(args.schemas_dir)    artifacts_root = pathlib.Path(args.artifacts_dir)    hard = bool(args.fail_on_invalid)    dialect = str(args.dialect)    max_depth = int(args.max_depth)    strict_dialect = bool(args.strict_dialect)    quiet = bool(args.quiet)    if not schemas_dir.exists():        print(f"missing schemas dir: {schemas_dir}")        if hard:            return 1    schemas, store, dialect_issues = load_schemas(schemas_dir, hard, dialect, quiet)    seen = 0    invalid: List[Tuple[str, str, str]] = []    # Traverse candidate run directories    for run_dir in iter_candidate_dirs(artifacts_root, max_depth):        for row in validate_dir(run_dir, schemas, schemas_dir, store, dialect):            invalid.append(row)        # Count artifacts seen in this directory        for artifact_name in SCHEMA_MAP.keys():            if (run_dir / artifact_name).exists():                seen += 1    if seen == 0:        print(f"no artifacts found under '{artifacts_root}' to validate")        if hard:            return 1    # Append dialect mismatch issues as invalids if strict    if strict_dialect:        for _, details in dialect_issues:            invalid.append(("schema-dialect", "dialect-mismatch", details))    if invalid:        print("INVALID ARTIFACTS DETECTED:")        for row in invalid:            # Each row is a tuple of strings. Join with spaces for readability.            # Format: path_or_tag reason details            print(" -", *row)        if hard:            return 1    if not invalid:        print("validation: ok")    else:        print("validation complete with issues")    return 0if __name__ == "__main__":    sys.exit(main())